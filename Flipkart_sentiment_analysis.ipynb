{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "30aaf07c-209e-47c9-867a-904991b24969",
      "cell_type": "code",
      "source": "conda create -n flipkart python=3.9\nconda activate flipkart\npip install flask nltk requests numpy bs4 matplotlib wordcloud",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6b7b739e-f932-424e-a91f-25e28fc14b79",
      "cell_type": "code",
      "source": "mport re\nimport os\nimport nltk\nimport joblib\nimport requests\nimport numpy as np\nfrom bs4 import BeautifulSoup\nimport urllib.request as urllib\nimport matplotlib.pyplot as plt\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud,STOPWORDS\nfrom flask import Flask,render_template,request\nimport time\n\n# Flipkart Reviews extraction and sentiment analysis\n# nltk.download('stopwords')\n# nltk.download('punkt')\n# nltk.download('wordnet')\n\napp = Flask(__name__)\napp.config['SEND_FILE_MAX_AGE_DEFAULT'] = 0\n\n\ndef clean(x):\n    x = re.sub(r'[^a-zA-Z ]', ' ', x) # replace evrything thats not an alphabet with a space\n    x = re.sub(r'\\s+', ' ', x) #replace multiple spaces with one space\n    x = re.sub(r'READ MORE', '', x) # remove READ MORE\n    x = x.lower()\n    x = x.split()\n    y = []\n    for i in x:\n        if len(i) >= 3:\n            if i == 'osm':\n                y.append('awesome')\n            elif i == 'nyc':\n                y.append('nice')\n            elif i == 'thanku':\n                y.append('thanks')\n            elif i == 'superb':\n                y.append('super')\n            else:\n                y.append(i)\n    return ' '.join(y)\n\n\ndef extract_all_reviews(url, clean_reviews, org_reviews,customernames,commentheads,ratings):\n    with urllib.urlopen(url) as u:\n        page = u.read()\n        page_html = BeautifulSoup(page, \"html.parser\")\n    reviews = page_html.find_all('div', {'class': 't-ZTKy'})\n    commentheads_ = page_html.find_all('p',{'class':'_2-N8zT'})\n    customernames_ = page_html.find_all('p',{'class':'_2sc7ZR _2V5EHH'})\n    ratings_ = page_html.find_all('div',{'class':['_3LWZlK _1BLPMq','_3LWZlK _32lA32 _1BLPMq','_3LWZlK _1rdVr6 _1BLPMq']})\n\n    for review in reviews:\n        x = review.get_text()\n        org_reviews.append(re.sub(r'READ MORE', '', x))\n        clean_reviews.append(clean(x))\n    \n    for cn in customernames_:\n        customernames.append('~'+cn.get_text())\n    \n    for ch in commentheads_:\n        commentheads.append(ch.get_text())\n    \n    ra = []\n    for r in ratings_:\n        try:\n            if int(r.get_text()) in [1,2,3,4,5]:\n                ra.append(int(r.get_text()))\n            else:\n                ra.append(0)\n        except:\n            ra.append(r.get_text())\n        \n    ratings += ra\n    print(ratings)\n\n\n@app.route('/')\ndef home():\n    return render_template('home.html')\n\n@app.route('/results',methods=['GET'])\ndef result():    \n    url = request.args.get('url')\n\n    nreviews = int(request.args.get('num'))\n    clean_reviews = []\n    org_reviews = []\n    customernames = []\n    commentheads = []\n    ratings = []\n\n    with urllib.urlopen(url) as u:\n        page = u.read()\n        page_html = BeautifulSoup(page, \"html.parser\")\n\n    proname = page_html.find_all('span', {'class': 'B_NuCI'})[0].get_text()\n    price = page_html.find_all('div', {'class': '_30jeq3 _16Jk6d'})[0].get_text()\n    \n    # getting the link of see all reviews button\n    all_reviews_url = page_html.find_all('div', {'class': 'col JOpGWq'})[0]\n    all_reviews_url = all_reviews_url.find_all('a')[-1]\n    all_reviews_url = 'https://www.flipkart.com'+all_reviews_url.get('href')\n    url2 = all_reviews_url+'&page=1'\n    \n\n    # start reading reviews and go to next page after all reviews are read \n    while True:\n        x = len(clean_reviews)\n        # extracting the reviews\n        extract_all_reviews(url2, clean_reviews, org_reviews,customernames,commentheads,ratings)\n        url2 = url2[:-1]+str(int(url2[-1])+1)\n        if x == len(clean_reviews) or len(clean_reviews)>=nreviews:break\n\n    org_reviews = org_reviews[:nreviews]\n    clean_reviews = clean_reviews[:nreviews]\n    customernames = customernames[:nreviews]\n    commentheads = commentheads[:nreviews]\n    ratings = ratings[:nreviews]\n\n\n    # building our wordcloud and saving it\n    for_wc = ' '.join(clean_reviews)\n    wcstops = set(STOPWORDS)\n    wc = WordCloud(width=1400,height=800,stopwords=wcstops,background_color='white').generate(for_wc)\n    plt.figure(figsize=(20,10), facecolor='k', edgecolor='k')\n    plt.imshow(wc, interpolation='bicubic') \n    plt.axis('off')\n    plt.tight_layout()\n    CleanCache(directory='static/images')\n    plt.savefig('static/images/woc.png')\n    plt.close()\n\n    \n    # making a dictionary of product attributes and saving all the products in a list\n    d = []\n    for i in range(len(org_reviews)):\n        x = {}\n        x['review'] = org_reviews[i]\n        # x['sent'] = predictions[i]\n        x['cn'] = customernames[i]\n        x['ch'] = commentheads[i]\n        x['stars'] = ratings[i]\n        d.append(x)\n    \n\n    for i in d:\n        if i['stars']!=0:\n            if i['stars'] in [1,2]:\n                i['sent'] = 'NEGATIVE'\n            else:\n                i['sent'] = 'POSITIVE'\n    \n\n    np,nn =0,0\n    for i in d:\n        if i['sent']=='NEGATIVE':nn+=1\n        else:np+=1\n\n    return render_template('result.html',dic=d,n=len(clean_reviews),nn=nn,np=np,proname=proname,price=price)\n    \n    \n@app.route('/wc')\ndef wc():\n    return render_template('wc.html')\n\n\nclass CleanCache:\n\t'''\n\tthis class is responsible to clear any residual csv and image files\n\tpresent due to the past searches made.\n\t'''\n\tdef __init__(self, directory=None):\n\t\tself.clean_path = directory\n\t\t# only proceed if directory is not empty\n\t\tif os.listdir(self.clean_path) != list():\n\t\t\t# iterate over the files and remove each file\n\t\t\tfiles = os.listdir(self.clean_path)\n\t\t\tfor fileName in files:\n\t\t\t\tprint(fileName)\n\t\t\t\tos.remove(os.path.join(self.clean_path,fileName))\n\t\tprint(\"cleaned!\")\n\n\nif __name__ == '__main__':\n    app.run(debug=True)\n\n# this was the code for Flipkart Reviews extraction and sentiment analysis",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'SyntaxError'>",
          "evalue": "invalid syntax (<ipython-input-1-a04f48429e96>, line 1)",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    mport re\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 1
    },
    {
      "id": "98382160-2c4a-46f8-9292-07e401b262ad",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}